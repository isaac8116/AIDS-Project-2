{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c21fc6d",
   "metadata": {},
   "source": [
    " ### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69d8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a15162",
   "metadata": {},
   "source": [
    "### **Set Up Reddit API Access**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b5cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='RhCT2FHyjBBd1AjbnqylMQ',\n",
    "    client_secret='A_wD-PpvLqLY9w-8VgB54hzkbHSuYA',\n",
    "    user_agent='Izowk'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a3a08",
   "metadata": {},
   "source": [
    "This block authenticates your script with Reddit’s API using the credentials from your Reddit Developer App.\n",
    "\n",
    "\n",
    "`client_id`, `client_secret`, and `user_agent` identify your script and allow access to public data like posts and comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e47a9e",
   "metadata": {},
   "source": [
    "### **Insert Product to Research**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDIT_NAME = \"ProductReviews\"    # Change this to your subreddit\n",
    "SEARCH_QUERY = \"flex tape\"           # Change this to your search term\n",
    "POST_LIMIT = 5                       # Max number of relevant posts to extract\n",
    "FILENAME = \"reddit_flex_tape\"        # Name of output file (no .csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387aee7",
   "metadata": {},
   "source": [
    "Here we define the variables that control our research:\n",
    "\n",
    "\n",
    "- `subreddit_name`: which subreddit to search in\n",
    "\n",
    "\n",
    "- `search_query` : product or term to search\n",
    "\n",
    "\n",
    "- `post_limit` : how many matching posts to extract (not how many comments!)\n",
    "\n",
    "\n",
    "- `filename` : the output CSV will be saved with this name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e896e1",
   "metadata": {},
   "source": [
    "### **Search Reddit & Extract Comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subreddit\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "# Store data here\n",
    "data = []\n",
    "valid_posts = 0\n",
    "\n",
    "print(f\"\\nSearching for '{search_query}' in r/{subreddit_name}...\\n\")\n",
    "\n",
    "for submission in subreddit.search(search_query, limit=100):\n",
    "    if submission.stickied:\n",
    "        continue  # Skip megathreads\n",
    "\n",
    "    print(f\"Scraping: {submission.title}\")\n",
    "    submission.comments.replace_more(limit=0)\n",
    "\n",
    "    for comment in submission.comments.list():\n",
    "        data.append({\n",
    "            'post_title': submission.title,\n",
    "            'post_url': submission.url,\n",
    "            'comment_body': comment.body,\n",
    "            'comment_author': str(comment.author),\n",
    "            'comment_score': comment.score,\n",
    "            'comment_created_utc': comment.created_utc\n",
    "        })\n",
    "\n",
    "    valid_posts += 1\n",
    "    if valid_posts >= post_limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1a80f",
   "metadata": {},
   "source": [
    "This block performs the main data collection process:\n",
    "\n",
    "- The script queries up to 100 Reddit posts matching the search term in the specified subreddit.\n",
    "\n",
    "\n",
    "- Posts that are marked as \"stickied\" (e.g., announcements or megathreads) are skipped to avoid unrelated or redundant data.\n",
    "\n",
    "\n",
    "- For each valid post, all associated comments—including nested replies—are retrieved and flattened using `.list()`.\n",
    "\n",
    "\n",
    "- Metadata such as post title, URL, comment content, author, score, and timestamp are extracted and stored.\n",
    "\n",
    "\n",
    "- The loop halts once the specified number (`post_limit`) of relevant posts has been processed.\n",
    "\n",
    "\n",
    "The collected data provides qualitative insight into how users discuss or evaluate the product across multiple posts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4921e0e",
   "metadata": {},
   "source": [
    "### **Create Dataframe and Save Comments to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "csv_filename = f\"{filename}.csv\"\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91952f2e",
   "metadata": {},
   "source": [
    "This line provides user feedback confirming the successful completion of the data collection and export process. \n",
    "\n",
    "It dynamically displays:\n",
    "\n",
    "\n",
    "- The total number of comments extracted and stored in the DataFrame (`len(df)`).\n",
    "\n",
    "\n",
    "- The name of the generated CSV file (`csv_filename`) that contains the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
